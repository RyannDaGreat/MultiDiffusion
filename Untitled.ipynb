{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75bea48-8bff-430c-abb4-08678c8689f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rp\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "from diffusers import DiffusionPipeline, DDIMScheduler\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46071ced-9adf-401e-8106-f1ca4acda9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment ONE model:\n",
    "# model_ckpt = \"stabilityai/stable-diffusion-2-base\"            ; scheduler_kwargs={}\n",
    "# model_ckpt = \"stabilityai/stable-diffusion-2-1-base\"          ; scheduler_kwargs={}\n",
    "# model_ckpt = \"stabilityai/stable-diffusion-xl-base-1.0\"       ; scheduler_kwargs={}\n",
    "# model_ckpt = \"ByteDance/sd2.1-base-zsnr-laionaes5\"            ; scheduler_kwargs = dict(timestep_spacing=\"trailing\",rescale_betas_zero_snr=True); rescale_betas_zero_snr=True  #Zero-terminal SNR; can use rescale_betas_zero_snr=True and timestep_spacing=\"trailing\"\n",
    "model_ckpt = \"ByteDance/sd2.1-base-zsnr-laionaes6-perceptual\" ; scheduler_kwargs = dict(timestep_spacing=\"trailing\",rescale_betas_zero_snr=True); guidance_scale=0 #Zero-terminal SNR + it uses guidance_scale=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ad444c-cec7-465e-aa79-f7041c1db328",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = DDIMScheduler.from_pretrained(\n",
    "    model_ckpt,\n",
    "    subfolder=\"scheduler\",\n",
    "    \n",
    "    # thresholding = True,\n",
    "    **scheduler_kwargs,\n",
    ")\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    model_ckpt, \n",
    "    scheduler=scheduler, \n",
    "    safety_checker=None,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "ic(pipe.scheduler.config.prediction_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99765eee-e0cf-4864-acbe-f1339c17dae5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for _ in range(20):\n",
    "    out=pipe(\n",
    "        \"\",\n",
    "        # \"A photo geisha isolated on a solid green background\",\n",
    "        guidance_scale=0, # Default: 7.5\n",
    "    )\n",
    "    images += out.images\n",
    "\n",
    "clear_output()\n",
    "rp.display_image(rp.tiled_images(images, length=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ca461b-2735-4429-9138-175c9a6f597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff876af-0888-4e72-97d8-8fabe95c341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6fbc35-4cb7-4534-8140-c72182f3e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_height = pipe.unet.config.sample_size\n",
    "latent_width  = pipe.unet.config.sample_size\n",
    "height = latent_height * pipe.vae_scale_factor\n",
    "width  = latent_width  * pipe.vae_scale_factor\n",
    "latent_num_channels = pipe.vae.config.latent_channels\n",
    "batch_size = 1\n",
    "pure_noise_latents = torch.randn(batch_size, latent_num_channels, latent_height, latent_width)\n",
    "pure_noise_latents = pure_noise_latents.to(pipe.dtype).to(pipe.device)\n",
    "\n",
    "ic(height, pipe.vae_scale_factor, latent_height)\n",
    "ic(pure_noise_latents.shape, pure_noise_latents.dtype, pure_noise_latents.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880574a5-4674-4295-a780-735aa5c3be80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# print(pure_noise_latent.flatten()[:10])\n",
    "# random.seed(123)\n",
    "# torch.random.manual_seed(213)\n",
    "\n",
    "pipe_output = pipe(\n",
    "    \"A cute puppy on an ocean\",\n",
    "    # \"A photo geisha isolated on a solid green background\",\n",
    "    guidance_scale=0, # Default: 7.5\n",
    "\n",
    "    latents = pure_noise_latents,\n",
    ")\n",
    "\n",
    "image = pipe_output.images[0]\n",
    "rp.display_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2978e6b9-bb33-4d15-9ed8-2056d7c11b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_as_image(latent, contrast=1/3, scale=8):\n",
    "    global height, width\n",
    "    latent=rp.as_numpy_image(latent)\n",
    "    latent=latent * contrast\n",
    "    latent+=1/2\n",
    "    latent=rp.cv_resize_image(latent, scale, interp='nearest')\n",
    "    return latent\n",
    "\n",
    "rp.display_image(latent_as_image(pure_noise_latents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b53a94e-47aa-4c6d-9665-3d55d5f6d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_torch_images(torch_images, dx=0, dy=0):\n",
    "    \"\"\"torch_images is in BCHW form\"\"\"\n",
    "    return torch_images.roll((dx,dy),(-1,-2))\n",
    "\n",
    "image_slideshow=[]\n",
    "for dx in range(20):\n",
    "    rolled_latents = roll_torch_images(pure_noise_latents, dx)\n",
    "    frame = latent_as_image(rolled_latents[0])\n",
    "    # frame = rp.with_alpha_checkerboard(frame, tile_size=128)\n",
    "    image_slideshow.append(frame)\n",
    "\n",
    "rp.display_image_slideshow(image_slideshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154d448-261f-4d90-ab43-34160bde330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_slideshow=[]\n",
    "\n",
    "shifts = range(64)\n",
    "display_eta = rp.eta(len(shifts))\n",
    "for i, dx in enumerate(shifts):    \n",
    "    rolled_latents = roll_torch_images(pure_noise_latents, dx)\n",
    "\n",
    "    pipe_output = pipe(\n",
    "        \"A cute puppy on an the beach\",\n",
    "        guidance_scale=guidance_scale,\n",
    "    \n",
    "        latents = rolled_latents,\n",
    "    )\n",
    "    \n",
    "    pipe_image = pipe_output.images[0]\n",
    "\n",
    "    frame = rp.horizontally_concatenated_images(\n",
    "        latent_as_image(rolled_latents[0]),\n",
    "        pipe_image,\n",
    "    )\n",
    "    \n",
    "    image_slideshow.append(frame)\n",
    "\n",
    "    clear_output()\n",
    "    display_eta(i)\n",
    "    rp.display_image(frame)\n",
    "\n",
    "clear_output()\n",
    "saved_video_path = rp.save_video_mp4(\n",
    "    image_slideshow,\n",
    "    rp.get_unique_copy_path('rolling_latents.mp4'),\n",
    "    framerate=15,\n",
    ")\n",
    "rp.fansi_print(\"Saved video: \"+saved_video_path, 'green')\n",
    "rp.display_image_slideshow(image_slideshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb605d1-938e-45e7-a7e2-c82bdc707ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python vaetuner",
   "language": "python",
   "name": "vaetuner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
