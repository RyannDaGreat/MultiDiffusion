{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75bea48-8bff-430c-abb4-08678c8689f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rp\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "from diffusers import DiffusionPipeline, DDIMScheduler\n",
    "from icecream import ic\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf99ebd-3d70-41b1-853f-201ed0674d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A cute puppy at the beach\"\n",
    "# prompt = \"a delicate apple made of opal hung on branch in the early morning light, adorned with glistening dewdrops. in the background beautiful valleys, divine iridescent glowing, opalescent textures, volumetric light, ethereal, sparkling, light inside body, bioluminescence, studio photo, highly detailed, sharp focus, photorealism, photorealism, 8k, best quality\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46071ced-9adf-401e-8106-f1ca4acda9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment ONE model:\n",
    "# model_ckpt = \"stabilityai/stable-diffusion-2-base\"            ; scheduler_kwargs={} ; guidance_scale=7.5\n",
    "model_ckpt = \"stabilityai/stable-diffusion-2-1-base\"          ; scheduler_kwargs={} ; guidance_scale=7.5\n",
    "# model_ckpt = \"stabilityai/stable-diffusion-xl-base-1.0\"       ; scheduler_kwargs={} ; guidance_scale=7.5\n",
    "# model_ckpt = \"ByteDance/sd2.1-base-zsnr-laionaes5\"            ; scheduler_kwargs = dict(timestep_spacing=\"trailing\",rescale_betas_zero_snr=True); rescale_betas_zero_snr=True  #Zero-terminal SNR; can use rescale_betas_zero_snr=True and timestep_spacing=\"trailing\"\n",
    "# model_ckpt = \"ByteDance/sd2.1-base-zsnr-laionaes6-perceptual\" ; scheduler_kwargs = dict(timestep_spacing=\"trailing\",rescale_betas_zero_snr=True); guidance_scale=0 #Zero-terminal SNR + it uses guidance_scale=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ad444c-cec7-465e-aa79-f7041c1db328",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = DDIMScheduler.from_pretrained(\n",
    "    model_ckpt,\n",
    "    subfolder=\"scheduler\",\n",
    "    \n",
    "    # thresholding = True,\n",
    "    **scheduler_kwargs,\n",
    ")\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    model_ckpt, \n",
    "    scheduler=scheduler, \n",
    "    safety_checker=None,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "ic(pipe.scheduler.config.prediction_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99765eee-e0cf-4864-acbe-f1339c17dae5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for _ in range(5):\n",
    "    out=pipe(\n",
    "        \"\",\n",
    "        guidance_scale=0, # Default: 7.5\n",
    "    )\n",
    "    images += out.images\n",
    "\n",
    "clear_output()\n",
    "rp.display_image(rp.tiled_images(images, length=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6fbc35-4cb7-4534-8140-c72182f3e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_height = pipe.unet.config.sample_size\n",
    "latent_width  = pipe.unet.config.sample_size\n",
    "height = latent_height * pipe.vae_scale_factor\n",
    "width  = latent_width  * pipe.vae_scale_factor\n",
    "latent_num_channels = pipe.vae.config.latent_channels\n",
    "batch_size = 1\n",
    "pure_noise_latents = torch.randn(batch_size, latent_num_channels, latent_height, latent_width)\n",
    "pure_noise_latents = pure_noise_latents.to(pipe.dtype).to(pipe.device)\n",
    "\n",
    "ic(height, pipe.vae_scale_factor, latent_height)\n",
    "ic(pure_noise_latents.shape, pure_noise_latents.dtype, pure_noise_latents.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880574a5-4674-4295-a780-735aa5c3be80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_output = pipe(\n",
    "    prompt,\n",
    "    guidance_scale=0, # Default: 7.5\n",
    "\n",
    "    latents = pure_noise_latents,\n",
    ")\n",
    "\n",
    "image = pipe_output.images[0]\n",
    "rp.display_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2978e6b9-bb33-4d15-9ed8-2056d7c11b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_as_image(latent, contrast=1/3, scale=8):\n",
    "    global height, width\n",
    "    latent=rp.as_numpy_image(latent)\n",
    "    latent=latent * contrast\n",
    "    latent+=1/2\n",
    "    latent=rp.cv_resize_image(latent, scale, interp='nearest')\n",
    "    return latent\n",
    "\n",
    "rp.display_image(latent_as_image(pure_noise_latents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b53a94e-47aa-4c6d-9665-3d55d5f6d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_torch_images(torch_images, dx=0, dy=0):\n",
    "    \"\"\"torch_images is in BCHW form\"\"\"\n",
    "    return torch_images.roll((dx,dy),(-1,-2))\n",
    "\n",
    "image_slideshow=[]\n",
    "for dx in range(20):\n",
    "    rolled_latents = roll_torch_images(pure_noise_latents, dx)\n",
    "    frame = latent_as_image(rolled_latents[0])\n",
    "    # frame = rp.with_alpha_checkerboard(frame, tile_size=128)\n",
    "    image_slideshow.append(frame)\n",
    "\n",
    "rp.display_image_slideshow(image_slideshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154d448-261f-4d90-ab43-34160bde330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_slideshow=[]\n",
    "\n",
    "shifts = range(64)\n",
    "display_eta = rp.eta(len(shifts))\n",
    "for i, dx in enumerate(shifts):    \n",
    "    rolled_latents = roll_torch_images(pure_noise_latents, dx)\n",
    "\n",
    "    pipe_output = pipe(\n",
    "        prompt,\n",
    "        guidance_scale=guidance_scale,\n",
    "        latents = rolled_latents,\n",
    "    )\n",
    "    pipe_image = pipe_output.images[0]    \n",
    "\n",
    "    frame = rp.horizontally_concatenated_images(\n",
    "        latent_as_image(rolled_latents[0]),\n",
    "        pipe_image,\n",
    "    )\n",
    "    \n",
    "    image_slideshow.append(frame)\n",
    "\n",
    "    clear_output()\n",
    "    display_eta(i)\n",
    "    rp.display_image(frame)\n",
    "\n",
    "clear_output()\n",
    "saved_video_path = rp.save_video_mp4(\n",
    "    image_slideshow,\n",
    "    rp.get_unique_copy_path('rolling_latents.mp4'),\n",
    "    framerate=15,\n",
    ")\n",
    "rp.fansi_print(\"Saved video: \"+saved_video_path, 'green')\n",
    "rp.display_image_slideshow(image_slideshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb605d1-938e-45e7-a7e2-c82bdc707ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_torch_latents_via_reencoding(latents, dx=0, dy=0):\n",
    "    \"\"\"Now dx and dy are in pixel space\"\"\"\n",
    "    with torch.no_grad():\n",
    "        latents = latents.to(pipe.dtype).to(pipe.device)\n",
    "    \n",
    "        #NOTE: This assumes the latents have the same mean/std as images\n",
    "        #Which is NOT a unit normal distribution! If given a unit normal,\n",
    "        #the accuracy will probably suffer as its out of distribution for\n",
    "        #the encoder and decoder. Nevertheless, lets see how it does!\n",
    "        factor = 1.0\n",
    "        factor = factor * pipe.vae.config.scaling_factor #Idk if this is what the number is for?\n",
    "        latents = latents / factor \n",
    "        \n",
    "        images = pipe.vae.decode(latents).sample\n",
    "        images = roll_torch_images(images, dx, dy)\n",
    "        latents = pipe.vae.encode(images).latent_dist.mean\n",
    "    \n",
    "        latents = latents * factor\n",
    "        \n",
    "        return latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b666f-4fd6-4dfa-8515-5580317f51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recursion test for redecoded_roll_torch_latents\n",
    "image_slideshow=[]\n",
    "recursed_latents = pure_noise_latents\n",
    "\n",
    "recursion_iterations = 20\n",
    "display_eta = rp.eta(recursion_iterations)\n",
    "for i in range(recursion_iterations):    \n",
    "    pipe_output = pipe(\n",
    "        prompt,\n",
    "        guidance_scale=guidance_scale,\n",
    "        latents = recursed_latents,\n",
    "    )\n",
    "    pipe_image = pipe_output.images[0]\n",
    "\n",
    "    frame = rp.horizontally_concatenated_images(\n",
    "        latent_as_image(recursed_latents[0]),\n",
    "        pipe_image,\n",
    "    )\n",
    "    frame = rp.labeled_image(frame, 'Recursion Iterations: '+str(i))\n",
    "    image_slideshow.append(frame)\n",
    "\n",
    "    clear_output()\n",
    "    display_eta(i)\n",
    "    rp.display_image(frame)\n",
    "\n",
    "    recursed_latents = roll_torch_latents_via_reencoding(recursed_latents)\n",
    "\n",
    "\n",
    "saved_video_path = rp.save_video_mp4(\n",
    "    image_slideshow,\n",
    "    rp.get_unique_copy_path('recused_latents.mp4'),\n",
    "    framerate=15,\n",
    ")\n",
    "clear_output()\n",
    "rp.fansi_print(\"Saved video: \"+saved_video_path, 'green')\n",
    "rp.display_image_slideshow(image_slideshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93128b88-a95d-49ff-ab76-b69b1f10ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_slideshow=[]\n",
    "\n",
    "shifts = range(30) #In pixels\n",
    "display_eta = rp.eta(len(shifts))\n",
    "for i,dx in enumerate(shifts):    \n",
    "    shifted_latents = roll_torch_latents_via_reencoding(pure_noise_latents, dx)\n",
    "    \n",
    "    pipe_output = pipe(\n",
    "        prompt,\n",
    "        guidance_scale=guidance_scale,\n",
    "        latents = shifted_latents,\n",
    "    )\n",
    "    pipe_image = pipe_output.images[0]\n",
    "\n",
    "    frame = rp.horizontally_concatenated_images(\n",
    "        latent_as_image(shifted_latents[0]),\n",
    "        pipe_image,\n",
    "    )\n",
    "    frame = rp.labeled_image(frame, 'Shift: dx='+str(dx)+\" pixels\")\n",
    "    image_slideshow.append(frame)\n",
    "\n",
    "    clear_output()\n",
    "    display_eta(i)\n",
    "    rp.display_image(frame)\n",
    "\n",
    "\n",
    "saved_video_path = rp.save_video_mp4(\n",
    "    image_slideshow,\n",
    "    rp.get_unique_copy_path('reencode_shifted_latents.mp4'),\n",
    "    framerate=15,\n",
    ")\n",
    "clear_output()\n",
    "rp.fansi_print(\"Saved video: \"+saved_video_path, 'green')\n",
    "rp.display_image_slideshow(image_slideshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19348c1e-e486-4277-b13f-035b6f82a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_slideshow=[]\n",
    "\n",
    "row_nums = range(64)\n",
    "display_eta = rp.eta(len(row_nums))\n",
    "for i,row_num in enumerate(row_nums):    \n",
    "    latents = pure_noise_latents.clone()\n",
    "    \n",
    "    latents[0,:,row_num,:]=0\n",
    "    \n",
    "    pipe_output = pipe(\n",
    "        prompt,\n",
    "        guidance_scale=guidance_scale,\n",
    "        latents = latents,\n",
    "    )\n",
    "    pipe_image = pipe_output.images[0]\n",
    "\n",
    "    frame = rp.horizontally_concatenated_images(\n",
    "        latent_as_image(latents[0]),\n",
    "        pipe_image,\n",
    "    )\n",
    "    frame = rp.labeled_image(frame, 'Set latent row #'+str(row_num)+\" to 0\")\n",
    "    image_slideshow.append(frame)\n",
    "\n",
    "    clear_output()\n",
    "    display_eta(i)\n",
    "    rp.display_image(frame)\n",
    "\n",
    "\n",
    "saved_video_path = rp.save_video_mp4(\n",
    "    image_slideshow,\n",
    "    rp.get_unique_copy_path('row_deletion.mp4'),\n",
    "    framerate=15,\n",
    ")\n",
    "clear_output()\n",
    "rp.fansi_print(\"Saved video: \"+saved_video_path, 'green')\n",
    "rp.display_image_slideshow(\n",
    "    rp.resize_images(image_slideshow, 1/4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5b43a7-3ac9-470a-8432-62adb4d7b4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_slideshow=[]\n",
    "\n",
    "col_nums = range(64)\n",
    "display_eta = rp.eta(len(col_nums))\n",
    "for i,col_num in enumerate(col_nums):    \n",
    "    latents = pure_noise_latents.clone()\n",
    "    \n",
    "    latents[0,:,:,col_num]=0\n",
    "    \n",
    "    pipe_output = pipe(\n",
    "        prompt,\n",
    "        guidance_scale=guidance_scale,\n",
    "        latents = latents,\n",
    "    )\n",
    "    pipe_image = pipe_output.images[0]\n",
    "\n",
    "    frame = rp.horizontally_concatenated_images(\n",
    "        latent_as_image(latents[0]),\n",
    "        pipe_image,\n",
    "    )\n",
    "    frame = rp.labeled_image(frame, 'Set latent col #'+str(col_num)+\" to 0\")\n",
    "    image_slideshow.append(frame)\n",
    "\n",
    "    clear_output()\n",
    "    display_eta(i)\n",
    "    rp.display_image(frame)\n",
    "\n",
    "\n",
    "saved_video_path = rp.save_video_mp4(\n",
    "    image_slideshow,\n",
    "    rp.get_unique_copy_path('col_deletion.mp4'),\n",
    "    framerate=15,\n",
    ")\n",
    "clear_output()\n",
    "rp.fansi_print(\"Saved video: \"+saved_video_path, 'green')\n",
    "rp.display_image_slideshow(\n",
    "    rp.resize_images(image_slideshow, size=1/4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf581a4-7259-48b2-b6db-0b116dd7ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_slideshow=[]\n",
    "\n",
    "upto_col_nums = range(64)\n",
    "display_eta = rp.eta(len(upto_col_nums))\n",
    "for i,upto_col_num in enumerate(upto_col_nums):    \n",
    "    latents = pure_noise_latents.clone()\n",
    "    \n",
    "    latents[0,:,:,:upto_col_num]=0\n",
    "    \n",
    "    pipe_output = pipe(\n",
    "        prompt,\n",
    "        guidance_scale=guidance_scale,\n",
    "        latents = latents,\n",
    "    )\n",
    "    pipe_image = pipe_output.images[0]\n",
    "\n",
    "    frame = rp.horizontally_concatenated_images(\n",
    "        latent_as_image(latents[0]),\n",
    "        pipe_image,\n",
    "    )\n",
    "    frame = rp.labeled_image(frame, 'Set latent upto_col #'+str(upto_col_num)+\" to 0\")\n",
    "    image_slideshow.append(frame)\n",
    "\n",
    "    clear_output()\n",
    "    display_eta(i)\n",
    "    rp.display_image(frame)\n",
    "\n",
    "\n",
    "saved_video_path = rp.save_video_mp4(\n",
    "    image_slideshow,\n",
    "    rp.get_unique_copy_path('upto_col_deletion.mp4'),\n",
    "    framerate=15,\n",
    ")\n",
    "clear_output()\n",
    "rp.fansi_print(\"Saved video: \"+saved_video_path, 'green')\n",
    "rp.display_image_slideshow(\n",
    "    rp.resize_images(image_slideshow, size=1/4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1191804f-ec92-4b63-ad42-5435804e2e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_slideshow=[]\n",
    "\n",
    "pixel_shifts = range(64)\n",
    "display_eta = rp.eta(len(pixel_shifts))\n",
    "for i, dx in enumerate(pixel_shifts):    \n",
    "\n",
    "    latent_shift = dx / 8\n",
    "    alpha = latent_shift % 1\n",
    "    rolled_latents_ceil  = roll_torch_images(pure_noise_latents, int(np.ceil (latent_shift)))\n",
    "    rolled_latents_floor = roll_torch_images(pure_noise_latents, int(np.floor(latent_shift)))\n",
    "    rolled_latents = rp.blend(rolled_latents_floor, rolled_latents_ceil, alpha)\n",
    "\n",
    "    pipe_output = pipe(\n",
    "        prompt,\n",
    "        guidance_scale=guidance_scale,\n",
    "        latents = rolled_latents,\n",
    "    )\n",
    "    pipe_image = pipe_output.images[0]    \n",
    "\n",
    "    frame = rp.horizontally_concatenated_images(\n",
    "        latent_as_image(rolled_latents[0]),\n",
    "        pipe_image,\n",
    "    )\n",
    "    frame = rp.labeled_image(frame, \"Blended latent shift, dx=\"+str(dx)+\" (pixel space)\")\n",
    "    \n",
    "    image_slideshow.append(frame)\n",
    "\n",
    "    clear_output()\n",
    "    display_eta(i)\n",
    "    rp.display_image(frame)\n",
    "\n",
    "clear_output()\n",
    "saved_video_path = rp.save_video_mp4(\n",
    "    image_slideshow,\n",
    "    rp.get_unique_copy_path('blended_rolling_latents.mp4'),\n",
    "    framerate=15,\n",
    ")\n",
    "rp.fansi_print(\"Saved video: \"+saved_video_path, 'green')\n",
    "rp.display_image_slideshow(rp.resize_images(image_slideshow, size=1/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f48fb3-aa95-4584-bc84-412f9b0f6aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_slideshow=[]\n",
    "\n",
    "pixel_shifts = range(64)\n",
    "display_eta = rp.eta(len(pixel_shifts))\n",
    "for i, dx in enumerate(pixel_shifts):    \n",
    "\n",
    "    latent_shift = dx / 8\n",
    "    alpha = latent_shift % 1\n",
    "    rolled_latents_floor = roll_torch_images(pure_noise_latents, int(np.floor(latent_shift)))\n",
    "    rolled_latents_ceil  = roll_torch_images(pure_noise_latents, int(np.ceil (latent_shift)))\n",
    "\n",
    "    #Unlike simple alpha blending, this preserves the variance\n",
    "    rolled_latents = ((1 - alpha) ** .5) * rolled_latents_floor + (alpha ** .5) * rolled_latents_ceil\n",
    "    ic(dx, rolled_latents.mean(), rolled_latents.std())\n",
    "\n",
    "    pipe_output = pipe(\n",
    "        prompt,\n",
    "        guidance_scale=guidance_scale,\n",
    "        latents = rolled_latents,\n",
    "    )\n",
    "    pipe_image = pipe_output.images[0]    \n",
    "\n",
    "    frame = rp.horizontally_concatenated_images(\n",
    "        latent_as_image(rolled_latents[0]),\n",
    "        pipe_image,\n",
    "    )\n",
    "    frame = rp.labeled_image(frame, \"Blended latent shift, dx=\"+str(dx)+\" (pixel space)\")\n",
    "    \n",
    "    image_slideshow.append(frame)\n",
    "\n",
    "    clear_output()\n",
    "    display_eta(i)\n",
    "    rp.display_image(frame)\n",
    "\n",
    "clear_output()\n",
    "saved_video_path = rp.save_video_mp4(\n",
    "    image_slideshow,\n",
    "    rp.get_unique_copy_path('variance_preserving_blended_rolling_latents.mp4'),\n",
    "    framerate=15,\n",
    ")\n",
    "rp.fansi_print(\"Saved video: \"+saved_video_path, 'green')\n",
    "rp.display_image_slideshow(rp.resize_images(image_slideshow, size=1/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c0113-b103-4f09-975b-2d9655ee452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_slideshow=[]\n",
    "\n",
    "shifts = range(64)\n",
    "display_eta = rp.eta(len(shifts))\n",
    "for i, dx in enumerate(shifts):    \n",
    "    tiled_latents = pure_noise_latents.clone()\n",
    "    # tiled_latents[:,:,:32,:32]=tiled_latents[:,:,:32,:32]\n",
    "    # tiled_latents[:,:,32:,:32]=tiled_latents[:,:,:32,:32]\n",
    "    # tiled_latents[:,:,32:,32:]=tiled_latents[:,:,:32,:32]\n",
    "    # tiled_latents[:,:,:32,32:]=tiled_latents[:,:,:32,:32]\n",
    "\n",
    "\n",
    "    tiled_latents[:,:,16:32,16:32] = 0\n",
    "    tiled_latents[:,:,32:,:32]\n",
    "    tiled_latents[:,:,32:,32:]\n",
    "    tiled_latents[:,:,:32,32:]\n",
    "    \n",
    "    rolled_latents = roll_torch_images(tiled_latents, dx)\n",
    "\n",
    "    pipe_output = pipe(\n",
    "        prompt,\n",
    "        guidance_scale=guidance_scale,\n",
    "        latents = rolled_latents,\n",
    "    )\n",
    "    pipe_image = pipe_output.images[0]    \n",
    "\n",
    "    frame = rp.horizontally_concatenated_images(\n",
    "        latent_as_image(rolled_latents[0]),\n",
    "        pipe_image,\n",
    "    )\n",
    "    \n",
    "    image_slideshow.append(frame)\n",
    "\n",
    "    clear_output()\n",
    "    display_eta(i)\n",
    "    rp.display_image(frame)\n",
    "\n",
    "clear_output()\n",
    "saved_video_path = rp.save_video_mp4(\n",
    "    image_slideshow,\n",
    "    rp.get_unique_copy_path('tiled_rolling_latents.mp4'),\n",
    "    framerate=15,\n",
    ")\n",
    "rp.fansi_print(\"Saved video: \"+saved_video_path, 'green')\n",
    "rp.display_image_slideshow(image_slideshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2fae71-a7b2-441c-8ae6-51acdabaff4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python vaetuner",
   "language": "python",
   "name": "vaetuner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
